# V5 Feature: ID-Based Deduplication

**Implemented:** 2025-10-01
**Version:** V5
**Status:** âœ… Complete

## Problem Statement

When running multiple tender discovery queries with overlapping parameters (same dates but different states, or overlapping date ranges), the system would re-fetch and re-process tenders already in the database. This wasted significant processing time on:

- Stage 2: Quick filtering (re-classifying known tenders)
- Stage 3: API sampling (making duplicate API calls)
- Stage 4: Full processing (re-extracting items)

### Example Scenarios

**Scenario 1: Same dates, different states**
```
Run 1: Fetch SP, Jul-Sep 2024 â†’ 3,940 tenders (34 min Stage 1)
Run 2: Fetch RJ, Jul-Sep 2024 â†’ 2,500 tenders (25 min Stage 1)
  Problem: Stages 2-4 would process all tenders, even if some overlap
```

**Scenario 2: Overlapping dates, same state**
```
Run 1: Fetch SP, Jul-Aug 2024 â†’ 2,000 tenders
Run 2: Fetch SP, Aug-Sep 2024 â†’ 2,500 tenders
  Problem: ~500 tenders from August are duplicates
```

**Scenario 3: Re-running same query**
```
Run 1: Fetch SP, Jul-Sep 2024 â†’ 3,940 tenders (full processing)
Run 2: Fetch SP, Jul-Sep 2024 â†’ 3,940 tenders (100% duplicates!)
  Problem: Wastes ALL Stages 2-4 processing time
```

## Solution: ID-Based Deduplication

Filter tenders by their unique PNCP control number (`numeroControlePNCP`) after Stage 1 (bulk fetch) but before Stage 2 (quick filter).

### Key Design Decisions

1. **Use PNCP's unique ID**: `numeroControlePNCP` (e.g., "12474705000120-1-000107/2024")
   - Already exists in API response
   - Already stored in database (`control_number` column with UNIQUE constraint)
   - Guaranteed unique across all PNCP tenders

2. **Filter after Stage 1, before Stage 2**
   - Can't avoid Stage 1 API fetching (need to query PNCP to know what exists)
   - Can avoid Stages 2-4 processing for known tenders

3. **Single efficient query**
   - Use PostgreSQL `ANY()` operator to check multiple IDs at once
   - Index on `control_number` for fast lookups (<1ms per tender)

## Implementation

### 1. Database Function (database.py:415-465)

```python
async def filter_new_tenders(self, fetched_tenders: List[Dict]) -> List[Dict]:
    """
    Filter out tenders that already exist in database by control number.
    Returns only NEW tenders that haven't been processed yet.

    This enables efficient deduplication across different states, dates, and modalities.
    """
    if not fetched_tenders:
        return []

    # Extract control numbers from fetched tenders
    control_numbers = [
        t.get('numeroControlePNCP')
        for t in fetched_tenders
        if t.get('numeroControlePNCP')
    ]

    if not control_numbers:
        logger.warning("No control numbers found in fetched tenders")
        return fetched_tenders

    conn = await self.db_manager.get_connection()
    try:
        # Query database for existing tenders by control number
        query = """
            SELECT control_number
            FROM tenders
            WHERE control_number = ANY($1)
        """

        existing_rows = await conn.fetch(query, control_numbers)
        existing_set = {row['control_number'] for row in existing_rows}

        # Filter to only new tenders
        new_tenders = [
            t for t in fetched_tenders
            if t.get('numeroControlePNCP') not in existing_set
        ]

        duplicates_count = len(fetched_tenders) - len(new_tenders)

        logger.info(
            f"Tender deduplication: {len(fetched_tenders)} fetched â†’ "
            f"{len(new_tenders)} new, {duplicates_count} already in DB "
            f"({duplicates_count/len(fetched_tenders)*100:.1f}% duplicates)"
        )

        return new_tenders

    finally:
        await conn.close()
```

### 2. Integration in Discovery Pipeline (optimized_discovery.py:119-131)

```python
# STAGE 1: Bulk fetch
raw_tenders = await self._stage1_bulk_fetch(state, start_date, end_date)
logger.info(f"ðŸ“¥ Stage 1 complete: {len(raw_tenders)} tenders fetched")

# DEDUPLICATION: Filter out tenders already in database (by control number)
new_tenders = await self.db_ops.filter_new_tenders(raw_tenders)
duplicates_filtered = len(raw_tenders) - len(new_tenders)
if duplicates_filtered > 0:
    logger.info(f"ðŸ”„ Deduplication: {duplicates_filtered} tenders already in DB, "
               f"{len(new_tenders)} new tenders to process")

# STAGE 2: Quick filter (zero API calls) - now only processes NEW tenders
quick_filtered = await self._stage2_quick_filter(new_tenders)
```

### 3. Database Index for Performance (database.py:240)

```sql
CREATE INDEX IF NOT EXISTS idx_tenders_control_number ON tenders(control_number);
```

This index ensures the deduplication query is lightning-fast, even with thousands of tenders.

## Benefits

### âœ… State-Agnostic
- Works when fetching different states with same dates
- SP and RJ tenders have different control numbers â†’ both processed

### âœ… Date-Agnostic
- Works with overlapping date ranges
- Only duplicate control numbers are filtered, regardless of date

### âœ… Modality-Agnostic
- Works with any combination of modalities
- Same control number = same tender, regardless of how it was fetched

### âœ… Exact Deduplication
- Based on PNCP's own unique IDs
- No false positives (won't skip tenders we need)
- No false negatives (will catch all duplicates)

### âœ… Fast Performance
- Indexed query: <1ms per tender check
- Batch query: Check 5,000 tenders in <1 second
- No noticeable overhead added to pipeline

## Performance Impact

### First Run (Empty Database)
- Deduplication overhead: <1 second
- Result: 0% duplicates filtered
- All tenders processed through Stages 2-4

### Second Run (Same Query)
- Deduplication overhead: <1 second
- Result: 100% duplicates filtered
- **Stages 2-4 completely skipped** (massive time saving!)

### Overlapping Run
- Deduplication overhead: <1 second
- Result: Only duplicates filtered (e.g., 500/2,500 = 20%)
- Stages 2-4 process only 2,000 new tenders instead of 2,500

### Example Time Savings (for re-run scenario)

**Without deduplication:**
- Stage 1: 34 min (fetch 3,940 tenders)
- Stage 2: 5 min (quick filter all 3,940)
- Stage 3: 22 min (sample duplicates)
- Stage 4: 10 min (process duplicates)
- **Total: 71 minutes**

**With deduplication:**
- Stage 1: 34 min (fetch 3,940 tenders)
- Deduplication: <1 sec (filter 3,940 duplicates)
- Stages 2-4: 0 min (nothing to process!)
- **Total: 34 minutes**

**Savings: 37 minutes (52% faster!)**

## Testing

Test script: `tests/test_deduplication.py`

```bash
python3 tests/test_deduplication.py
```

This verifies:
- âœ… Correctly identifies existing tenders
- âœ… Correctly identifies new tenders
- âœ… Handles edge cases (empty list, all new, all duplicates)
- âœ… Performance is acceptable (<1 second for typical batch)

## Future Enhancements

### Potential Optimization: Bloom Filter
For very large databases (>100K tenders), consider adding a Bloom filter:

```python
# Pre-load Bloom filter on startup
bloom = BloomFilter(capacity=100000, error_rate=0.01)
for control_num in await db.fetch("SELECT control_number FROM tenders"):
    bloom.add(control_num)

# Fast negative check (99% certain NOT in DB)
async def filter_new_tenders_optimized(tenders):
    # Quick Bloom filter pass
    likely_new = [t for t in tenders if t['numeroControlePNCP'] not in bloom]

    # Verify with database (catch false positives)
    return await filter_new_tenders(likely_new)
```

**Benefit:** Reduces database queries by 90%+ when most tenders are new
**Cost:** ~1MB memory for 100K tenders
**When to implement:** When database has >50K tenders

## Related Documentation

- [OPTIMIZATION_PLAN.md](../OPTIMIZATION_PLAN.md) - Strategy 7
- [Database Schema](../database.py) - Tenders table, line 134-157
- [Optimized Discovery](../optimized_discovery.py) - Pipeline integration

## Version History

- **V5 (2025-10-01)**: Initial implementation with control_number deduplication
- **Future**: Consider Bloom filter optimization for large databases
